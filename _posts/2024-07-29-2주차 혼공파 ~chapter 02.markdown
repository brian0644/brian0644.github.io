---
layout: post
title:  "ML 2주차 정리"
date:   2024-07-29 14:00 +09:00
categories: khuda ML session
---
# **1. 나의 첫 머신러닝**
## 1-1. 인공지능과 머신러닝, 딥러닝
 * 인공지능 : 강인공지능(사람과 구분하기 어려울 정도의 지능을 가진) // 약인공지능(특정 분야에서 사람의 일을 도와주는 보조 역할)
 * 머신러닝 : 규칙을 일일이 프로그래밍하지 않아도 자동으로 데이터에서 규칙을 학습하는 알고리즘을 연구하는 분야
 * 딥러닝 : 머신러닝 알고리즘 중에 인공 신경망을 기반으로 한 방법들을 통칭하여 딥러닝이라고 부른다 << 텐서플로우라는 구글 딥러닝 라이브러리로
  
  
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


## 1-2 코랩과 주피터 노트북
 * 구글 코랩 : 웹 브라우저에서 무료로 파이썬 프로그램을 테스트하고 저장할 수 있는 서비스. 머신러닝 프로그램도 개발 가능. 클라우드 기반의 주피터 노트북 >> 컴퓨터 성능 상관 없음
<br>
<br>
 * 텍스트 셀 : 텍스트를 입력는 창. 텍스트 셀에서는 HTML과 Markdown을 혼용해서 사용 가능
<br>
<img width="600" alt="스크린샷 2024-07-29 오후 2 37 09" src="https://github.com/user-attachments/assets/e1a9c092-5588-417c-ac6d-e02501ee49b2">
<br>
<br>
  * 코드 셀 : 코드를 입력하고 실행할 수 있는 창
<br>
<img width="343" alt="스크린샷 2024-07-29 오후 2 27 53" src="https://github.com/user-attachments/assets/27b1f1d9-b494-4295-ba6a-576043a24233">
<br>
<br>
 * 노트북 : 대화식 프로그래밍 환경. VM(가상 서버)를 통해 메모리 12기가 및 디스크 100기가까지 무료로 이용 가능, 그러나 코랩 노트북으로 동시에 사용할 수 있는 가상 서버는 최대 5개


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 

  
## 1-3 마켓과 머신러닝
  
  
### 생선 분류 문제
  생선을 분류하기 위해서는 생선의 특징을 알면 쉽게 구분할 수 있을 것 
  -> 특징을 알아내고자 일단 도미의 데이터셋 생성  
  
```python
bream_length = [25.4, 26.3, 26.5, 29.0, 29.0, 29.7, 29.7, 30.0, 30.0, 30.7, 31.0, 31.0, 31.5, 32.0, 32.0, 32.0, 33.0, 33.0, 33.5, 33.5, 34.0, 34.0, 34.5, 35.0, 35.0, 35.0, 35.0, 36.0, 36.0, 37.0, 38.5, 38.5, 39.5, 41.0, 41.0]  # 도미의 길이
bream_weight = [242.0, 290.0, 340.0, 363.0, 430.0, 450.0, 500.0, 390.0, 450.0, 500.0, 475.0, 500.0, 500.0, 340.0, 600.0, 600.0, 700.0, 700.0, 610.0, 650.0, 575.0, 685.0, 620.0, 680.0, 700.0, 725.0, 720.0, 714.0, 850.0, 1000.0, 920.0, 955.0, 925.0, 975.0, 950.0] # 도미의 무게
```

 이렇게 단순히 데이터를 숫자로 보는 것보다 그래프로 표현하면 데이터를 잘 이해할 수 있음 -> matplotlib 패키지 임포트

```python
import matplotlib.pyplot as plt
plt.scatter(bream_length,bream_weight)
plt.xlabel("length")
plt.ylabel("weight")
plt.show()
```  
<img width="1014" alt="스크린샷 2024-07-29 오후 3 05 21" src="https://github.com/user-attachments/assets/5a8391ba-ac4c-4e78-83a6-4dde95d168d2">

 **결과 : 생선 길이에 따라 무게가 선형적으로 증가하는 관계로 해석 가능**
  
 도미 데이터를 확인했으니 이제 빙어 데이터 준비 및 시각화
  
```python
smelt_length = [9.8, 10.5, 10.6, 11.0, 11.2, 11.3, 11.8, 11.8, 12.0, 12.2, 12.4, 13.0, 14.3, 15.0] # 빙어 길이
smelt_weight = [6.7, 7.5, 7.0, 9.7, 9.8, 8.7, 10.0, 9.9, 9.8, 12.2, 13.4, 12.2, 19.7, 19.9]        # 빙어 무게

plt.scatter(bream_length,bream_weight)
plt.scatter(smelt_length,smelt_weight)
plt.xlabel("length")
plt.ylabel("weight")
plt.show()
```  
<img width="1003" alt="스크린샷 2024-07-29 오후 3 10 52" src="https://github.com/user-attachments/assets/7b467d7e-6d35-4577-a782-2308830e429d">
 
 **결과 : 빙어 데이터는 주황색, 빙어도 도미와 비슷하게 길이와 무게에 비례하지만 그 기울기가 도미보단 작아보임**
<br>
<br>
<br>
<br>
<br>
#### k-Nearest Neighbors 알고리즘
<br>
<img width="511" alt="스크린샷 2024-07-29 오후 3 41 14" src="https://github.com/user-attachments/assets/bf40077e-3c02-41d3-9095-3534948942f5">
<br>
    * 원리는 이와 같다. K-NN으로 학습된 모델에 데이터를 입력하면 해당 데이터와 유사한(주위의 : nearest) 다른 데이터를 보고 다수를 차지하는 것을 정답으로 사용
    
    * 기본적으로 가까운 데이터로 선정되는 개수는 5개 , 새로운 모델 = KNeighborsClassifier(n_neighbors = 숫자), kn.n_neighbors = n 를 통해 선정할 데이터 개수 선택 가능

    * KNeighborsClassifier(p=), P 매개변수가 1이면 맨해튼 거리, 2면 유클리디안, 기본값은 2
<br>
  
```python
fish_data = [[l,w] for l,w in zip(length,weight)] # knn 알고리즘을 사용하기 위해 도미와 빙어 데이터 하나로 합치기 (데이버를 합쳐서 구분 못하게) -> 사이킷런 패키지를 사용하기 위해 2차원 리스트로 수정

fish_target = [1] * 35 + [0] * 14                 # 0~34번 인덱스까지는 1 = 도미 , 36~49번 인덱스까지는 0 = 빙어
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier()                       # KNeighborsClassifier 클래스의 객체 생성
kn.fit(fish_data, fish_target)                    # kn 객체에 데이터와 정답을 전달 -> 학습
kn.score(fish_data, fish_target)                  # kn.score(데이터, 정답)으로 학습 잘 되었는지 확인
kn.predict([[30,600]])                            # predict 함수에 입력한 값이 잘 분류 되는 지 확인


for n in range(5, 50):                           
    kn.n_neighbors = n                            # 최근접 이웃 개수 설정
    score = kn.score(fish_data, fish_target)      # 점수 계산
    if score < 1:                                 # 100% 정확도에 미치지 못하는 이웃 개수 출력
        print(n, score)
        break
```  
  
**정리하자면**<br>
1. 데이터를 2차원 배열로 준비하기
2. 데이터에 대한 정답을 2차원 배열로 준비하기
3. kn = KNeighborsClassifier()으로 학습모델 생성 후 kn.fit(데이터, 정답)로 학습
4. kn.score(데이터, 정답)으로 학습 잘 되었는지 확인, kn.predict(데이터)로 잘 분류하는지 확인


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 



# **2. 데이터 다루기**  
## 2-1 훈련세트와 테스트 세트 
* 지도학습 : 데이터(input)과 정답(target)을 둘다 학습시키는 것. 타깃이 있으니 정답을 맞히는 모델 생성
* 비지도학습 : 데이터(input)만 학습 시키는 것. 무언가를 맞힐 수는 없지만 데이터를 잘 파악하거나 변형하는 데 도움을 줌
* 훈련 세트 : 훈련에 사용되는 데이터
* 테스트 세트 : 테스트에 사용되는 데이터
* 샘플링 편향 : 데이터를 훈련 세트와 테스트 세트로 나누는 과정에서 샘플들이 골고루 섞이지 않은 경우
* 넘파이 : 배열 라이브러리, 파이썬의 리스트로 2차원 리스트를 표현할 수 있지만 고차원 리스트를 표현하기 위해 필요함
<br>

```python
input_arr = np.array(fish_data)    # 데이터를 넘파이 배열로 변환
target_arr = np.array(fish_target) # 정답을 넘파이 배열로 변환
                                   # print(input_arr.shape = 샘플 수, 특성 수)

np.random.seed(42)
index = np.arange(49)               # 넘파이 arange() -> 0부터 48까지 1씩 증가하는 인덱스 생성
np.random.shuffle(index)            # 인덱스를 랜덤하게 섞기
                                    # print(input_arr[[1,3]]) -> 배열 인덱싱 기능으로 1개의 인덱스가 아닌 여러개의 인덱스로 한 번에 여러개의 원소 선택
train_input = input_arr[index[:35]]     # 무작위로 선택된 인덱스 35개를 훈련용 데이터로 선택
train_target = target_arr[index[:35]]   # 무작위로 선택된 인덱스 35개를 훈련용 타깃으로 선택
test_input = input_arr[index[35:]]      # 무작위로 선택된 인덱스 14개를 테스트용 데이터로 선택
test_target = target_arr[index[35:]]    # 무작위로 선택된 인덱스 14개를 테스트용 데이터로 선택

kn = KNeighborsClassifier()
kn = kn.fit(train_input, train_target) # 훈련용 데이터와 타깃으로 모델 학습
kn.score(test_input, test_target)      # 테스트용 데이터와 타깃으로 모델 평가
kn.predict(test_input)                 # 테스트용 데이터로 예측 했을 때 test_target과 일치 하는것을 확인 가능

```

**정리하자면**<br>
1. 2차원 배열 데이터를 넘파이 array()함수를 통해 넘파이 배열로 변환
2. seed()를 통해 난수를 생성하기 위한 정수 초깃값 지정 후 49개의 인덱스 생성, shuffle()을 통해 주어진 배열을 랜덤하게 섞기
3. 훈련용 데이터, 타깃과 테스트용 데이터, 타깃으로 구분
4. fit()에 훈련용 데이터, 타깃을 넣고 score()에 테스트용 데이터, 타깃을 넣어봄으로써 모델 성능 평가


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 


\
두 번째 머신러닝 프로그램



02-2 데이터 전처리
넘파이로 데이터 준비하기
사이킷런으로 훈련 세트와 테스트 세트 나누기
수상한 도미 한 마리
기준을 맞춰라
전처리 데이터로 모델 훈련하기
스케일이 다른 특성 처리##








