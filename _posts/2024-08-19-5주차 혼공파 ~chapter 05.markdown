---
layout: post
title:  "ML 5주차 정리"
date:   2024-08-19 15:54 +09:00
categories: khuda ML session
---

# 5. 트리 알고리즘
## 5-1. 결정 트리
* 결정트리 :
  다른 분류 모델보다 이해하기 쉬우며 루트 노드와 리프 노드로 이루어져있다
  루트노드에서 쓰인 특성이 가장 유용한 특성 중 하나로 쓰이는 척도가 될 수 있다
  
    
<img width="723" alt="스크린샷 2024-08-19 오후 4 15 51" src="https://github.com/user-attachments/assets/169366b5-fb7b-4db1-b5c4-209c9f000baa">

    
* 불순도 :

  **gini**
  
  gini는 지니 불순도를 의미한다. 매개변수 기본값이 gini이며 지니 불순도는 1-(음성 클래스 비율^2 + 양성 클래스 비율^2) 로 이루어져있다.
  결정 트리 모델은 부모 노드와 자식 노드의 불순도 차이가 가능한 크도록(한쪽 클래스의 비율을 더 높이도록) 트리를 성장시킨다
  먼저 자식 노드의 불순도를 샘플 개수에 비례하여 모두 더하고 부모 노드의 불순도에서 뺀다
  이런 부모와 자식 노드 사이의 불순도 차리를 **정보 이득** 이라고 부른다.

  **entropy**
  
  entropy는 엔트로피 불순도를 의미한다. 엔트로피 불순도도 노드의 클래스 비율을 사용하지만 지니 불순도처럼 제곱이 아니라 밑이 인 로그를 사용하여 곱한다.
  
  
* 가지치기 :
  결정트리의 규제는 가지치기를 통해 이루어진다. 훈련세트에 적합한 노드를 일부 제거함으로써 과대적합을 방지하는 원리
  가지치기를 하는 가장 간단한 방법은 자라날 수 있는 트리의 최대 깊이를 지정하는 것 -> **DecisionTreeClassfier 클래스의 max_depth 매개변수를 조정**
  
  
```python
# 결정트리 패키지 임포트 후 학습
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(train_scaled, train_target)
print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))
# -> train점수가 test보다 높기 때문에 과대적합, 규제할 필요 있음


# plot tree를 통해 결정 트리 시각화하기
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
plt.figure(figsize=(10,7))
plot_tree(dt)
plt.show()


# 그림이 너무 복잡하니 트리의 깊이를 제한해서 출력
# max_depth 변수를 1로 주면 루트 노드를 제외하고 하나의 노드를 더 확장하여 그림
# filled 변수에서 클래스에 맞게 노드 색 칠하기
# feature_names 변수에서 특성의 이름을 전달하기\
plt.figure(figsize=(10,7))
plot_tree(dt, max_depth=1, filled = True, feature_names=['alcohol','sugar','pH'])
plt.show()
# -> value = [음성 클래스, 양성 클래스], value 값은 분류 결과가 아니라 해당 노드에서 가지는 양음성 클래스 데이터의 개수일뿐


# max_depth = 3으로 지정해서 재학습
dt = DecisionTreeClassifier(max_depth= 3,random_state=42)
dt.fit(train_scaled, train_target)
print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))


# plot tree를 통해 결정 트리 시각화하기
plt.figure(figsize=(10,7))
plot_tree(dt, filled = True, feature_names=['alcohol','sugar','pH'])
plt.show() 


# feature_importances_ 속성에 저장된 특성별 중요도 출력
print(dt.feature_importances_)


# 가지치기 max_depth 말고 min_impurity_decrease 사용해보기
# 어떤 노드의 정보이득 x (노드의 샘플 수) / (전체 샘플 수) 값이 이 매개변수보다 작으면 더이상 분할하지 않음
dt = DecisionTreeClassifier(min_impurity_decrease = 0.0005,random_state=42)
dt.fit(train_input, train_target)
print(dt.score(train_input, train_target))
print(dt.score(test_input, test_target))
plt.figure(figsize=(20,15), dpi =300)
plot_tree(dt, filled = True, feature_names=['alcohol','sugar','pH'])
plt.show() 

```



## 5-2. 교차 검증과 그리드 서치
* 검증 세트 :
  
일반적으로 테스트 세트로 일반화 성능을 올바르게 예측하려면 가능한 한 테스트 세트를 사용하지 말아야한다<br>
모델을 만들고 나서 마지막에 딱 한번만 사용하는 것이 좋다<br>
그렇다면 max_depth 매개변수를 사용한 하이퍼파라미터 튜닝을 어떻게 할 수 있을까 + 결정트리는 테스트해 볼 매개변수가 많다<br>
-> 테스트 세트를 사용하지 않으면 모델이 과대적합인지 과소적합인지 판단하기 어려움 -> 훈련세트를 또 나누어 검증세트로 활용
<br>

```python
# 훈련세트에서 또 20%를 떼와서 검증 세트로 준비
sub_input, val_input, sub_target, val_target = train_test_split(train_input,train_target,test_size=0.2,random_state=42)
print(sub_input.shape, val_input.shape)


# 결정 트리 학습
# 결정트리 패키지 임포트 후 학습
# 이제 훈련된 모델은 검증 세트로 평가, 최종 점수는 테스트 세트로
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)
print(dt.score(sub_input, sub_target))
print(dt.score(val_input, val_target))


# k-fold cross check 수행
# cross_validate 함수 임포트 후 (모델, 훈련세트 전체)를 전달
# 각 결과는 fit_time, score_time,test_score 키를 가진 딕셔너리 반환, cv 매개 변수는 k-fold의 k개 결정
from sklearn.model_selection import cross_validate
scores = cross_validate(dt, train_input, train_target)
print(scores)
 

# 검증 세트에 대한 점수 평균치 계산
print(np.mean(scores['test_score']))
```

* 교차 검증 :
  
보통 많은 데이터를 훈련에 사용할수록 좋은 모델이 만들어짐<br>
그렇다고 검증 세트를 너무 조금 떼어 놓으면 검증 점수가 들쭉날쭉하고 불안정할것<br>
이럴 때 **교차검증**을 이용하면 안정적인 검증 점수를 얻고 훈련에 더 많은 데이터 사용 가능<br>
교차 검증은 검증 세트를 떼어 내어 평가하는 과정을 여러 번 반복함<br>
그다음 이점수를 평균하여 최종 검증 점수를 얻어냄

<img width="539" alt="스크린샷 2024-08-19 오후 4 49 04" src="https://github.com/user-attachments/assets/c4872202-3717-40f9-a462-d9599001245e">

이러한 과정을 3-fold cross check라고 부름 (훈련 세트를 세 부분으로 나누어 교차 검증 수행, k-fold cross check라고 부름)<br>
사이킷 런에는 cross_validate()라는 교차 검증 함수가 존재, 평가할 모델 객체를 첫 번째 매개변수로, 그다음 앞에서처럼 직접 검증 세트를 떼어 내지 않고 훈련 세트 전체를 함수에 전달<br>
cross_validate는 훈련 세트를 섞어서 폴드로 나누지 않기 때문에 분할기(splitter)를 지정해야함


```python
# 사이킷런의 분할기는 교차 검증에서 폴드를 어떻게 나눌지 결정
# cross_validate() 함수는 기본적으로 회귀 모델일 경우 KFold 분할기를 사용하고
# 분류 모델일 경우 타깃 클래스를 골고루 나누기 위해 StratifiedKFold를 사용
from sklearn.model_selection import StratifiedKFold
scores = cross_validate(dt, train_input, train_target, cv=StratifiedKFold())
print(np.mean(scores['test_score']))


# 훈련 세트를 섞은 후 10-Fold cross check 수행
# n_splits 는 k를 지정 -> k개로 훈련세트를 나눠야하니까
# shuffle 은 데이터 랜덤하기 섞기
splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_validate(dt, train_input, train_target, cv=splitter)
print(np.mean(scores['test_score']))
```



* 하이퍼파라미터 튜닝 :
  **그리드 서치**
  
머신러닝 모델에서 사용자가 지정해야만 하는 파라미터를 하이퍼파라미터라고 부름<br>
이런 하이퍼파라미터 튜닝은 모델마다 적게는 1~2개, 많게는 5~6개 제공<br>
이 매개변수를 바꿔가면서 모델을 훈련하고 교차 검증 수행(사람의 개입 없이 하이퍼파라미터 튜닝을 자동으로 하는 기술을 'AutoML'이라고 부름)<br>
각 하이퍼파라미터의 최적값은 다른 하이퍼파라미터의 변화에 영향받음 -> 여러개의 매개변수를 동시에 바꿔가며 최적의 값을 찾아야함<br>
for 반복문으로 이런 과정을 직접 구현할 수도 있지만 사이킷런에서 제공하는 **그리드 서치**를 사용하면 됨<br>
사이킷런의 GridSearchCV 클래스는 하이퍼파라미터 탐색과 교차 검증을 한번에 수행 -> cross_validate() 함수를 호출할 필요 없음



```python
# 그리드 서치
# 기본 매개변수를 사용한 결정 트리 모델에서 min_impurity_decrease의 최적값 찾기
# 먼저 GridSearchCV 클래스 임포트, 탐색할 매개변수와 탐색할 값의 리스트를 딕셔너리에 담기
from sklearn.model_selection import GridSearchCV
params = {'min_impurity_decrease': [0.0001, 0.0002, 0.0003, 0.0004, 0.0005]}



# GridSearchCV 클래스에 탐색 대상 모델과 params 변수를 전달하여 그리드 서치 객체 생성 (모델, 하이퍼파라미터의 다양한 값)
# GridSearchCV의 cv는 기본값이 5, 즉 5개의 리스트 값에 대한 5-폴드 교차 검증 수행 -> 총 25개의 모델 훈련
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)


# 검증 점수가 가장 높은 모델의 값은 gs 객체의 best_estimator_ 속성에 저장
dt = gs.best_estimator_
print(dt.score(train_input, train_target))


# 그리드 서치로 찾은 최적의 매개변수는 best_params_ 속성에 저장
print(gs.best_params_)


# cv_results_ 속성의 'mean_test_score'키에서 5번의 교차 검증으로 얻은 점수 출력
print(gs.cv_results_['mean_test_score'])


# 이제 min_impuritiy_decrease와 max_depth, min_samples_split 3개의 하이퍼파라미터 튜닝
# np.arange는 첫 번째 매개변수 값에서 시작하여 두 번째 매개변수에 도달할 대까지 세 번째 매개변수를 계속 더한 배열
# 파이썬의 range는 같은 기능이지만 정수만 가능 
parmas = {'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001), 'max_depth': range(5, 20, 1), 'min_samples_split': range(2, 100, 10)}


# 각 하이퍼파라미터 튜닝을 위한 그리드 서치 실행
gs = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1)
gs.fit(train_input, train_target)
print(gs.best_params_)


# 최상의 교차 검증 점수도 확인
print(np.max(gs.cv_results_['mean_test_score']))

```


  **랜덤 서치**
매개변수의 값이 수치일 때, 값의 범위나 간격을 미리 정하기 어려울 수 있음<br>
또 너무 많은 매개변수 조건이 있어 그리드 서치 수행 시간이 오래 걸릴 수 있음<br>
이럴 때 **랜덤 서치**를 사용하면 좋음<br>
랜덤 서치에는 매개변수 값의 목록을 전달하는 것이 아니라 매개변수를 샘플링할 수 있는 확률 분포 객체를 전달


```python
# 랜덤 서치
# 먼저 싸이파이에서 2개의 확률 분포 클래스 임포트
# randint 에서는 정수 추출
from scipy.stats import uniform, randint
rgen = randint(0,10)
rgen.rvs(10)

# 10개밖에 안되니까 고르게 샘플링 되지 않음 -> 샘플링 숫자를 늘리면 쉽게 확인 가능
np.unique(rgen.rvs(1000), return_counts=True)

# uniform 에서는 실수 추출
ugen = uniform(0,1)
ugen.rvs(10)



# 이 로직은 마치 난수 발생기. 랜덤 서치에서 randint와 uniform 클래스 객체를 넘겨주고 총 몇번을 샘플링 해서 최적의 매개변수를 찾아라 명령
# 샘플링 횟수는 시스템 자원이 허락하는 범위 내에서 최대한 크게 하는 것이 좋음
# 탐색할 매개변수의 딕셔너리 만들기, min_samples_leaf(리프 노드가 되기 위한 최소 샘플의 개수) 매개변수 추가
params = {'min_impurity_decrease': uniform(0.0001, 0.001), 'max_depth': randint(20,50), 'min_samples_split': randint(2, 25), 'min_samples_leaf': randint(1, 25),}


# 샘플링 횟수는 사이킷런의 랜덤 서치 클래스인 RandomizedSearchCV의 n_iter 매개변수에 지정, 출력
from sklearn.model_selection import RandomizedSearchCV
gs = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), params,n_iter=100, n_jobs=-1, random_state=42)
gs.fit(train_input, train_target)
print(gs.best_params_)
print(np.max(gs.cv_results_['mean_test_score']))
dt = gs.best_estimator_
print(dt.score(test_input, test_target))

# -> 테스트 세트에 대한 점수는 검증 세트에 대한 점수보다 조금 작은 것이 일반적.

```





## 5-3. 트리의 앙상블
* 앙상블 학습 :
  
  * 정형 데이터 : 어떤 구조로 되어있으며 csv나 데이터베이스, 엑셀에 저장하기 쉬운 데이터들<br>
  * 비정형 데이터 : 책의 글과 같은 텍스트 데이터, 사진, 음악 등 <br>
-> 이중 정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘이 **앙상블 학습** 이다

* 랜덤 포레스트 :
  
앙상블 학습 방법 중 하나로 안정적인 성능 덕분에 널리 사용되고 있는 기법<br>
이름 자체로 유추할 수 있듯이 랜덤 포레스트는 결정 트리를 랜덤하게 만들어 결정 트리의 "숲"을 만드는 셈<br>
그리고 각 결정 트리의 예측을 사용해 최종 예측을 만듬<br>
<br>
각 트리를 훈련하기 위한 데이터를 랜덤하게 만듬 (우리가 입력한 훈련 데이터에서 랜덤하게 샘플을 추출하여 훈련 데이터를 만들며, 한 샘플이 중복 추출 가능) -> 부트스트랩 샘플 -> OOB 샘플 발생<br>
이때 부트스트랩 샘플은 훈련세트의 크기와 같게 만듬.<br>
또한 각 노드를 분할할 때 전체 특성 중에서 일부 특성을 무작위로 고른 다음 이 중에서 최선의 분할을 찾는다<br>
분류모델인 RandomForestClassfier은 기본적으로 전체 특성 개수의 제곱근 만큼 특성을 선택, 그중에서 최선의 분할 특성을 선택하는 방식<br>
사이킷런의 랜덤 포레스트는 기본적으로 100개의 결정 트리를 이런 방식으로 훈련, 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측으로 삼는다<br>
랜덤 포레스트는 랜덤하게 선택한 샘플과 특성을 사용하기 때문에 훈련 세트에 과대적합되는 것을 막아주고 검증 세트와 테스트 세트에서 안정적인 성능을 얻을 수 있다<br>
**사이킷런의 RandomForestClassifier**


```python
# 데이터 준비
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
wine = pd.read_csv('https://bit.ly/wine-date')
wine_input = wine[['alcohol','sugar','pH']].to_numpy()
wine_target = wine['class'].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(wine_input,wine_target,test_size=0.2,random_state=42)



# 랜덤포레스트 모델 생성 후 교차검증 수행
# 사이킷런의 랜덤포레스트는 기본적으로 100개의 결정 트리를 사용하므로 모든 코어를 사용하는게 좋음
from sklearn.model_selection import cross_validate
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_jobs=-1, random_state=42)
scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))
# -> 훈련 점수가 더 높은 것으로 보아 과대적합 발생



# 랜덤포레스트 또한 결정 트리 모델을 사용하기 때문에 매개변수 또한 동일하게 제공한다
# 결정트리의 큰 장점은 특성 중요도를 계산할 수 있다는 점이다
# 랜덤 포레스트의 특성 중요도는 각 결정 트리의 특성 중요도를 취합한 것이다 -> 특성 중요도 출력해보기
rf.fit(train_input, train_target)
print(rf.feature_importances_)
# -> 이전 결정 트리 특성 중요도와 비교했을때 랜덤 포레스트 모델의 특성 중요도는 당도 중요도 감소, 알콜 도수, ph 중요도 조금 상승 -> 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회를 얻기 때문




# 랜덤 포레스트에는 자체적으로 모델을 평가하는 점수를 출력 가능
# 랜덤 포레스트는 훈련 세트에서 중복을 허용하여 부트스트랩 샘플을 만들다보니 포함되지 않는 샘플이 존재하기도 함
# 이런 샘플을 OOB 샘플이라고 부름
# 이 남는 OOB 샘플로 검증 세트 역할 수행
# oob_score = True -> OOB 샘플로 평균 점수 출력

rf = RandomForestClassifier(oob_score=True ,n_jobs=-1, random_state=42)
rf.fit(train_input, train_target)
print(rf.oob_score_)
```


* 엑스트라 트리 :
  
랜덤 포레스트와 매우 비슷하게 작동 -> 기본적으로 100개의 결정 트리를 훈련하고 결정 트리의 매개변수를 지원<br>
엑스트라 트리가 무작위성이 더 크기 때문에 랜덤 포레스트보다 더 많은 결정 트리를 훈련, 하지만 랜덤하게 노드를 분할하다보니 계산이 빠름<br>
하나의 결정 트리에서 특성을 무작위로 분할하면 성능이 낮아지겠지만 많은 트리를 앙상블 하기 때문에 과대적합을 막고 검증 세트의 점수를 높이는 효과 존재<br>
**사이킷런의 ExtraTreesclassifier**

```python
# 엑스트라 트리 임포트 후 학습
from sklearn.ensemble import ExtraTreesClassifier
et = ExtraTreesClassifier(n_jobs=-1, random_state=42)
scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))


# 엑스트라 트리 특성 중요도 출력
et.fit(train_input, train_target)
print(et.feature_importances_)
```

* 그레이디언트 부스팅 :
  
깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식<br>
**사이킷런의 GradientBoostingClassifier**은 기본적으로 깊이가 3인 결정트리 100개 제공<br>
깊이가 얕은 결정트리를 사용하기 때문에 과대적합에 강하고 일반적으로 높은 일반화 성능 기대 가능<br>
그레이디언트 부스팅은 결정 트리를 계속 추가하면서 손실함수의 낮은 곳으로 천천히 이동하는 방식 -> 학습률 매개변수로 속도 조절 가능<br>
그레이디언트 부스팅의 subsample은 트리 훈련에 사용할 훈련 세트의 비율을 정함<br>
이 매개변수는 기본값 1.0, 더 작으면 당연히 훈련 세트의 일부만 사용 -> 이는 마치 경사 하강법에서 확률적 경사 하강법이나 미니배치 경사 하강법과 비슷<br>
일반적으로 그레이디언트 부스팅이 랜덤 포레스트보다 조금 더 높은 성능을 얻을 수는 있지만 순서대로 트리를 추가하기 떄문에 속도가 느리다




```python
# 그레이디언트 임포트 후 모델 학습
from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier(random_state=42)
scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))




# 그레이디언트 부스팅은 결정 트리의 개수를 늘려도 과대적합에 매우 강하며 학습률을 증가시키고 트리의 개수를 늘리면 조금 더 성능이 향상 가능
gb = GradientBoostingClassifier(n_estimators=500, learning_rate= 0.2, random_state=42)
scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))



# 그레이디언트 부스팅에서 특성 중요도 출력
gb.fit(train_input, train_target)
print(gb.feature_importances_)
```


* 히스토그램 기반 그레이디언트 부스팅 :
  
정형 데이터를 다루는 머신러닝 알고리즘 중에 가장 인기가 높은 알고리즘<br>
입력 특성을 256개의 구간으로 나누기 때문에 노드를 분할할 때 최적의 분할을 매우 빠르게 찾을 수 있음<br>
256개의 구간 중에서 하나를 떼어놨다가 누락된 값을 찾을때 사용 -> 입력에 누락된 특성이 있더라도 이를 따로 전처리할 필요 없음<br>
**사이킷런의 HistGradientBoostingClassifier**은 기본적으로 트리의 개수를 max_iter로 조정


```python
# 히스토그램 기반 그레이디언트 부스팅 임포트 후 모델 학습
from sklearn.ensemble import HistGradientBoostingClassifier
hgb = HistGradientBoostingClassifier(random_state=42)
scores = cross_validate(hgb, train_input, train_target, return_train_score=True)
print(np.mean(scores['train_score']), np.mean(scores['test_score']))




# 히스토그램 기반 그레이디언트 부스팅에서 특성 중요도 출력
hgb.fit(train_input, train_target)
print(rf.feature_importances_)
hgb.score(test_input, test_target)



# colab에서 XGBoost를 통해 사용 가능
# from xgboost import XGBClassifier
# xgb = XGBClassifier(tree_method='hist', random_state=42)
# scores = cross_validate(xgb, train_input, train_target, return_train_score=True)
# print(np.mean(scores['train_score']), np.mean(scores['test_score']))


# colab에서 LightGBM을 통해 사용 가능
# from lightgbm import LGBMClassifier
# lgb = LGBMClassifier(random_state=42)
# scores = cross_validate(lgb, test_input, test_target, return_train_score=True)
# print(np.mean(scores['train_score']), np.mean(scores['test_score']))
```



