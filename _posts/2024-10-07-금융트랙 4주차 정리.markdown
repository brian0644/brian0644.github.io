---
layout: post
title:  "금융트랙 4주차 정리"
date:   2024-10-07 17:56+09:00
categories: khuda finance track
---
# 자연어 처리
* 금융에서 NLP는 일찍이 미국 증권거래위원회에서 활용되었는데, SEC는 회계 사기를 탐지하기 위해 텍스트 마이닝과 자연어 처리를 사용했다
* 법률 및 기타 문서를 고속으로 스캔하고 분석하는 NLP 알고리즘의 능력은 은행과 그 외 금융기관이 이 규정을 준수하고 사기를 방지하는 데 엄청난 효율성을 제공한다
* 다양한 보고서, 문서의 분석과 해석에 심층적 지원을 제공할 수 있다. 이렇게 반복적이고 부가가치가 낮은 직업이 직원에게 가하는 부담을 줄임
* 인적 오류로 인한 실수도 줄인다


## 자연어 처리 패키지 및 용어 정리
* 파이썬 패키지
  * NLTK, TextBlob, spaCy
 
* 전처리
  * 일반적으로 NLP에서 텍스트 데이터의 전처리는 여러 단계를 거친다
  * 토큰화 : 텍스트를 토큰이라고 하는 의미 있는 세그먼트로 분할하는 작업이다. 세그먼트는 문장의 구성요소인 단어, 구두점, 숫자 또는 기타 특수 문자일 수 있다
  * 불용어 제거 : 모델링에 값을 거의 제공하지 않는 매우 일반적인 단어는 종종 어휘에서 제거
  * 형태소 분석 : 변형된 단어를 어간, 어기 또는 어근 형식으로 줄이는 과정
  * 기본형식화 : 형태소 분석을 약간 변형한 것이 기본형식화
  * 품사 태깅 : PoS은 문장에서의 역할을 이해하기 위해 문법 범주에 토큰을 할당하는 과정
  * 명명 개체 인식 : 텍스트에서 명명된 개체를 찾아 미리 정의된 범주로 분류하려는 데이터 전처리 다음 단계
  * 근데 spaCy는 한번에 이걸 처리함 ㅋㅋㅋ

* 특성 표현
  *  뉴스 피드 기사, PDF 보고서, 소셜 미디어 게시물, 오디오 파일 같은 대부분의 NLP 관련 데이터는 사람이 사용할 수 있도록 생성된다 -> 컴퓨터에서 쉽게 처리할 수 없는 구조화되지 않은 형식
  * 단어 모음 - 단어 수 : 자연어 처리에서 텍스트에서 특성을 추출하는 일반적인 기술은 텍스트에서 발생한 모든 단어를 버킷에 배치하는 것 -> 이 접근 방식을 단어 모음 모델
    * 텍스트 모음에서 단일 행렬을 만들며 각 행은 토큰을 나타내고 각 열은 말뭉치의 문서 또는 무장을 나타낸다. 행렬의 값은 나타나는 토큰의 인스턴스 수를 나타낸다
    <img width="391" alt="스크린샷 2024-10-09 오후 1 54 57" src="https://github.com/user-attachments/assets/c9366c72-0518-4325-8345-20ae6a188958">
  * 단어 빈도 - 역문서 빈도 :  더 흥미로운 단어를 강조하는 단어 빈도 점수. 문서를 토큰화하고 어휘 및 역문서 빈도 가중치를 학습하며 새 문서를 인코딩 할 수 있다
  * 단어 임베딩 : 조밀한 벡터 표현을 사용해 단어와 문서를 나타낸다. 임베딩에서 단어는 조밀한 벡터로 표현되며 연속 벡터 공간으로의 단어 투영을 나타낸다
  * 추론 : 인공지능 작업과 마찬가지로 NLP 활용에서 생성된 추론은 일반적으로 실행 가능하도록 결정으로 변환되어야 한다
    * 지도 학습 Naive Bayes : 주어진 샘플의 범주를 예측하는 데 사용되며 특성이 다른 특성과 서로 독립적이라는 단순한 가정으로 베이즈의 정리를 적용한 알고리즘이다
    * 비지도 학습 LDA : 인간이 해석할 수 있는 의미 있는 주제를 생성하고 새 문서에 주제를 할당하며 확장 한다. 주제를 먼저 선택해 문서를 생성한 다음 각 주제에 대해 일련의 단어를 선택해 문서를 생성한다



## 실전 문제 1 : NLP 및 감정 분석 기반 거래 전략
* 자연어 처리는 텍스트를 수량화하는 기능을 제공한다. 다음과 같은 질문을 할 수 있다
  * 이 뉴스가 얼마나 긍정적입니까 부정적입니까
  * 단어를 어떻게 수량화할 수 있습니까
* 아마도 NLP의 가장 주목할 만한 활용은 알고리즘 거래에서의 사용 사례일 것이다 by 시장 감정 모니터링 (뉴스 기사, 보고서, 소셜 미디어 또는 기타 웹 콘텐츠에 적용하면 해당 소스의 감정 점수가 긍정적인지 부정적인지 판단 가능)


-> 따라서 해당 프로젝트는 NLP를 사용해 뉴스 헤드라인에서 정보 추출, 추출한 정보에 감정 할당, 감정 분석을 사용해 거래 전략 구축 이렇게 세가지 단계로 구성되었다

1. 뉴스 헤드라인 정보 추출
  * 여러 뉴스 웹사이트의 RSS 피드에서 수집된 뉴스 헤드라인 데이터, 주식 데이터를 위한 야후 파이낸스 웹사이트, 캐글, 주식 시장 사전의 데이터를 입력
  * 뉴스 내용을 JSON 형식 파일로 다운로드, JSON 파일 안에서 뉴스가 나온 부분을 HTML 구문 분석을 수행하여 추출

2. 추출한 정보에 감정 할당
  * TextBlob 패키지를 사용해 -1에서 +1 범위의 감정 극성 점수에 매핑해 문장을 숫자값으로 변환한다
  * 뉴스와 감정 사이에 강한 상관 관계가 없음을 알 수 있으며, 수익과 감정의 상관관계는 긍정적인 감정이 있는 뉴스가 긍정적인 수익으로 이어지고 기대된다는 것을 해석할 수 있다
  * 그러나 상관관계는 그다지 높지 않으며 전체 산점도를 보면 대부분의 감정이 0에 집중되었음을 알 수 있다 (TextBlob이 영화 평론 감정 점수라...)

3. 감정 분석을 사용해 거래 전략 구축
  * 시장의 감정을 분석했으니 이에 맞는 매수 매도 포지션 세팅

## 실전 문제 2 : 챗봇 디지털 도우미
* 챗봇은 사용자가 자연어로 대화하는 컴퓨터 프로그램. 사용자의 의도를 이해하고 조직의 비지니스 규칙과 데이터를 기반으로 응답할 수 있다
* 규칙 기반 : 다양한 챗봇은 규칙에 따라 학습된다. 이러한 챗봇은 상호작용을 통해 학습하지 않으며 때떄로 정의된 규칙을 벗어난 복잡한 쿼리에는 응답하지 못할 수 있다
* 자기 학습 : 머신러닝 및 인공지능 기술에 의존해 사용자와 대화한다. 자가 학습 챗봇은 검색 기반 및 생성 방식으로 세분화 한다
* ChatterBot : 챗봇 패키지
  * 논리 어댑터 :  주어진 입력 문장에 대한 응답을 선택하는 방법의 논리를 결정한다
  * 전처리기 : 논리 어댑터가 문장을 처리하기 전에 챗봇이 수신하는 입력 문장을 수정하는 간단한 함수
  * 말뭉치 훈련 : 말뭉치 데이터, 유틸리티 모듈과 함께 제공되어 봇이 통신하도록 신속하게 훈련할 수 있다
  * 훈련 목록 : ListTrainer을 사용해 훈련에 이용할 수 있는 대화로 챗봇을 훈련한다
* 일반적으로 적당량의 훈련 데이터를 얻는 것이 사용자 지정 챗봇을 구성할 때 가장 어려움


## 실전 문데 3 : 문서 요약
* 문서에서 가장 중요한 요점과 주제를 선택하고 포괄적인 방식으로 배열하는 것을 말한다
* 앞서 논의한 바와 같이 은행 및 기타 금융 서비스 조직의 분석가는 뉴스. 보고서, 문서 등의 질적 데이터를 조사하고 분석하며 정량화하려고 시도한다
* Pdf-miner는 pdf파일을 텍스트 형식으로 처리하는 데 사용
* PDF 문서에서 이미지를 제외하고 모든 문자를 가져와서 추출하고 파이썬 문자열 목록으로 출력한다
* 주제 시각화
  * 인간은 판단을 사용해 주제 품질을 쉽게 평가할 수 있다
  * pyLDAvis는 주제간의 전체 관계를 표시하는 동시에 각 주제와 가장 밀접하게 연관된 용어와 반대로 각 용어와 연관된 주제를 검사해 의미론적 평가를 용이하게 하는 라이브러리이다
<img width="343" alt="스크린샷 2024-10-09 오후 2 47 26" src="https://github.com/user-attachments/assets/318278dc-73fd-43e6-bc55-49ffb38fd23d">
  * 이런식으로 가장 자주 사용되는 용어를 메모하기 위해 전체 문서에 대한 단어 클라우드도 생성 가능









