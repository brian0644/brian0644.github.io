---
layout: post
title:  "금융트랙 4주차 정리"
date:   2024-10-07 17:56+09:00
categories: khuda finance track
---
# 자연어 처리
* 금융에서 NLP는 일찍이 미국 증권거래위원회에서 활용되었는데, SEC는 회계 사기를 탐지하기 위해 텍스트 마이닝과 자연어 처리를 사용했다
* 법률 및 기타 문서를 고속으로 스캔하고 분석하는 NLP 알고리즘의 능력은 은행과 그 외 금융기관이 이 규정을 준수하고 사기를 방지하는 데 엄청난 효율성을 제공한다
* 다양한 보고서, 문서의 분석과 해석에 심층적 지원을 제공할 수 있다. 이렇게 반복적이고 부가가치가 낮은 직업이 직원에게 가하는 부담을 줄임
* 인적 오류로 인한 실수도 줄인다


## 자연어 처리 패키지 및 용어 정리
* 파이썬 패키지
  * NLTK, TextBlob, spaCy
 
* 전처리
  * 일반적으로 NLP에서 텍스트 데이터의 전처리는 여러 단계를 거친다
  * 토큰화 : 텍스트를 토큰이라고 하는 의미 있는 세그먼트로 분할하는 작업이다. 세그먼트는 문장의 구성요소인 단어, 구두점, 숫자 또는 기타 특수 문자일 수 있다
  * 불용어 제거 : 모델링에 값을 거의 제공하지 않는 매우 일반적인 단어는 종종 어휘에서 제거
  * 형태소 분석 : 변형된 단어를 어간, 어기 또는 어근 형식으로 줄이는 과정
  * 기본형식화 : 형태소 분석을 약간 변형한 것이 기본형식화
  * 품사 태깅 : PoS은 문장에서의 역할을 이해하기 위해 문법 범주에 토큰을 할당하는 과정
  * 명명 개체 인식 : 텍스트에서 명명된 개체를 찾아 미리 정의된 범주로 분류하려는 데이터 전처리 다음 단계
  * 근데 spaCy는 한번에 이걸 처리함 ㅋㅋㅋ

* 특성 표현
  *  뉴스 피드 기사, PDF 보고서, 소셜 미디어 게시물, 오디오 파일 같은 대부분의 NLP 관련 데이터는 사람이 사용할 수 있도록 생성된다 -> 컴퓨터에서 쉽게 처리할 수 없는 구조화되지 않은 형식
  * 단어 모음 - 단어 수 : 자연어 처리에서 텍스트에서 특성을 추출하는 일반적인 기술은 텍스트에서 발생한 모든 단어를 버킷에 배치하는 것 -> 이 접근 방식을 단어 모음 모델
    * 텍스트 모음에서 단일 행렬을 만들며 각 행은 토큰을 나타내고 각 열은 말뭉치의 문서 또는 무장을 나타낸다. 행렬의 값은 나타나는 토큰의 인스턴스 수를 나타낸다
    <img width="391" alt="스크린샷 2024-10-09 오후 1 54 57" src="https://github.com/user-attachments/assets/c9366c72-0518-4325-8345-20ae6a188958">
  * 단어 빈도 - 역문서 빈도 :  더 흥미로운 단어를 강조하는 단어 빈도 점수. 문서를 토큰화하고 어휘 및 역문서 빈도 가중치를 학습하며 새 문서를 인코딩 할 수 있다
  * 단어 임베딩 : 조밀한 벡터 표현을 사용해 단어와 문서를 나타낸다. 임베딩에서 단어는 조밀한 벡터로 표현되며 연속 벡터 공간으로의 단어 투영을 나타낸다
  * 추론 : 인공지능 작업과 마찬가지로 NLP 활용에서 생성된 추론은 일반적으로 실행 가능하도록 결정으로 변환되어야 한다
    * 지도 학습 Naive Bayes : 주어진 샘플의 범주를 예측하는 데 사용되며 특성이 다른 특성과 서로 독립적이라는 단순한 가정으로 베이즈의 정리를 적용한 알고리즘이다
    * 비지도 학습 LDA : 인간이 해석할 수 있는 의미 있는 주제를 생성하고 새 문서에 주제를 할당하며 확장 한다. 주제를 먼저 선택해 문서를 생성한 다음 각 주제에 대해 일련의 단어를 선택해 문서를 생성한다



## 실전 문제 1 : NLP 및 감정 분석 기반 거래 전략
* 자연어 처리는 텍스트를 수량화하는 기능을 제공한다. 다음과 같은 질문을 할 수 있다
  * 이 뉴스가 얼마나 긍정적입니까 부정적입니까
  * 단어를 어떻게 수량화할 수 있습니까
* 아마도 NLP의 가장 주목할 만한 활용은 알고리즘 거래에서의 사용 사례일 것이다 by 시장 감정 모니터링 (뉴스 기사, 보고서, 소셜 미디어 또는 기타 웹 콘텐츠에 적용하면 해당 소스의 감정 점수가 긍정적인지 부정적인지 판단 가능)


-> 따라서 해당 프로젝트는 NLP를 사용해 뉴스 헤드라인에서 정보 추출, 추출한 정보에 감정 할당, 감정 분석을 사용해 거래 전략 구축 이렇게 세가지 단계로 구성되었다

1. 뉴스 헤드라인 정보 추출
  * 여러 뉴스 웹사이트의 RSS 피드에서 수집된 뉴스 헤드라인 데이터, 주식 데이터를 위한 야후 파이낸스 웹사이트, 캐글, 주식 시장 사전의 데이터를 입력
  * 뉴스 내용을 JSON 형식 파일로 다운로드, JSON 파일 안에서 뉴스가 나온 부분을 HTML 구문 분석을 수행하여 추출

2. 추출한 정보에 감정 할당
  * TextBlob 패키지를 사용해 -1에서 +1 범위의 감정 극성 점수에 매핑해 문장을 숫자값으로 변환한다
  * 뉴스와 감정 사이에 강한 상관 관계가 없음을 알 수 있으며, 수익과 감정의 상관관계는 긍정적인 감정이 있는 뉴스가 긍정적인 수익으로 이어지고 기대된다는 것을 해석할 수 있다
  * 그러나 상관관계는 그다지 높지 않으며 전체 산점도를 보면 대부분의 감정이 0에 집중되었음을 알 수 있다 (TextBlob이 영화 평론 감정 점수라...)

3. 감정 분석을 사용해 거래 전략 구축
  * 시장의 감정을 분석했으니 이에 맞는 매수 매도 포지션 세팅

## 실전 문제 2 : 챗봇 디지털 도우미
* 챗봇은 사용자가 자연어로 대화하는 컴퓨터 프로그램. 사용자의 의도를 이해하고 조직의 비지니스 규칙과 데이터를 기반으로 응답할 수 있다
* 규칙 기반 : 다양한 챗봇은 규칙에 따라 학습된다. 이러한 챗봇은 상호작용을 통해 학습하지 않으며 때떄로 정의된 규칙을 벗어난 복잡한 쿼리에는 응답하지 못할 수 있다
* 자기 학습 : 머신러닝 및 인공지능 기술에 의존해 사용자와 대화한다. 자가 학습 챗봇은 검색 기반 및 생성 방식으로 세분화 한다
* ChatterBot : 챗봇 패키지
  * 논리 어댑터 :  주어진 입력 문장에 대한 응답을 선택하는 방법의 논리를 결정한다
  * 전처리기 : 논리 어댑터가 문장을 처리하기 전에 챗봇이 수신하는 입력 문장을 수정하는 간단한 함수
  * 말뭉치 훈련 : 말뭉치 데이터, 유틸리티 모듈과 함께 제공되어 봇이 통신하도록 신속하게 훈련할 수 있다
  * 훈련 목록 : ListTrainer을 사용해 훈련에 이용할 수 있는 대화로 챗봇을 훈련한다
* 일반적으로 적당량의 훈련 데이터를 얻는 것이 사용자 지정 챗봇을 구성할 때 가장 어려움


## 실전 문데 3 : 문서 요약
* 문서에서 가장 중요한 요점과 주제를 선택하고 포괄적인 방식으로 배열하는 것을 말한다
* 앞서 논의한 바와 같이 은행 및 기타 금융 서비스 조직의 분석가는 뉴스. 보고서, 문서 등의 질적 데이터를 조사하고 분석하며 정량화하려고 시도한다
* Pdf-miner는 pdf파일을 텍스트 형식으로 처리하는 데 사용
* PDF 문서에서 이미지를 제외하고 모든 문자를 가져와서 추출하고 파이썬 문자열 목록으로 출력한다
* 주제 시각화
  * 인간은 판단을 사용해 주제 품질을 쉽게 평가할 수 있다
  * pyLDAvis는 주제간의 전체 관계를 표시하는 동시에 각 주제와 가장 밀접하게 연관된 용어와 반대로 각 용어와 연관된 주제를 검사해 의미론적 평가를 용이하게 하는 라이브러리이다
<img width="343" alt="스크린샷 2024-10-09 오후 2 47 26" src="https://github.com/user-attachments/assets/318278dc-73fd-43e6-bc55-49ffb38fd23d">
  * 이런식으로 가장 자주 사용되는 용어를 메모하기 위해 전체 문서에 대한 단어 클라우드도 생성 가능


# 평균-분산 전략 구현 및 시뮬레이션 분석

* 평균-분산 전략을 선택했다면, 룩백 기간과 리밸런싱 주기를 정해야함(하이퍼 파라미터로써) >> 시뮬레이션을 통해 룩백 기간과 리밸런싱 주기 선택 가능 (가장 좋았던 성과를 보인 파라미터로)
* 투자 전략을 시뮬레이션 하기 위해서 1. 데이터 수집, 2. 투자 전략, 3. 시뮬레이션, 4. 시뮬레이션 분석의 개발 단계로 진행.
  * 투자전략 개발 단계에는 투자 유니버스를 정의하고 평균 분산 모델 최적화와 같은 자산 배분 알고리즘 개발
  * 시뮬레이션 개발 단계에서는 실제 금융 거래 환경을 재현하기 위해 거래에 참옇나느 투자자, 중개인과 같은 참여자들을 모델링 하고 주문 생성, 거래 실행, 거래비용 처리, 결과 기록과 같은 프로세스 구현
<img width="231" alt="스크린샷 2024-10-09 오후 3 44 44" src="https://github.com/user-attachments/assets/c82d2b51-e38d-4a2e-817a-2013c8e78e4a">


## 데이터 수집
평균 분산 전략 시뮬레이션을 구현하기 위한 첫 번째 단계로 어떤 데이터가 필요하고 어떻게 수집할 수 있는지 확인해보자
<br>
종목은 코스피 대표 종목 9가지
<img width="571" alt="스크린샷 2024-10-09 오후 3 45 49" src="https://github.com/user-attachments/assets/94d92b07-0abd-41d8-8cc5-ed10611a2a99">

이렇게 선택할 예정이며 시뮬레이션 기간은 2020년 7월 10일 ~ 2023년 9월 27일로 설정
<br>
* 시뮬레이션을 수행하기 위해서는 우선 해당 종목의 주가 데이터가 필요하므로 한국 증권 시장의 주가 데이터를 수집하기 위해 PyKrx라는 파이썬 라이브러리 사용
* 해당 라이브러리는 한국 거래소등의 국내 주요 주식 정보 제공 웹사이트에서 시장 데이터를 스크래핑 할 수 있는 API 제공

<img width="426" alt="스크린샷 2024-10-09 오후 3 47 20" src="https://github.com/user-attachments/assets/3581ed45-c084-445b-b236-f14d5b99fcbd">

## 평균 분산 최적화
이제 평균 분산 모델의 최적화를 구현하는 과정을 살펴보자. 평균 분산 모델을 적용하기 위해서는 자산의 기대 수익률과 공분산 행렬이 필요하다
<img width="283" alt="스크린샷 2024-10-09 오후 3 49 52" src="https://github.com/user-attachments/assets/5abd7daa-845f-4db6-9afc-18b65a06cea1">

가장 쉬운 방법은 자산의 과거 수익률 데이터를 사용해서 계산하는 방법. 즉 자산의 평균 수익률을 기대 수익률로, 수익률 표본 공분산 행렬을 자산 간 공분산 행렬로 계산
* pyPortfolioOpt를 사용하는 방식으로 투자 포트폴리오 최적화를 진행한다
  * 기대 수익률 추정 : 과거 데이터를 이용한 기대 수익률을 추정
  * 위험도 추정 : 과거 데이터를 이요해서 수익률의 공분산 행렬을 정의
  * 최적화할 목적 함수 : 자산 배분을 수행할 평균-분산 모델의 목적함수 선택
  * 옵티마이저 : 주어진 자산 목록에서 평균-분산 모델의 최적화를 수행해 최적의 포트폴리오의 자산 편입 비중을 계산

```python
def calculate_return(ohlcv_data: pd.DataFrame):
    close_data = ohlcv_data[['close', 'ticker']].reset_index().set_index(
        ['ticker', 'date'])
    close_data = close_data.unstack(level=0)
    close_data = close_data['close']
    return_data = close_data.pct_change(1) * 100
    return return_data


def get_mean_variance_weights(return_data: pd.DataFrame,
                              risk_aversion: int) -> Optional[Dict]:
    # 수익률 계산
    expected_return = return_data.mean(skipna=False).to_list()
    # 공분산 행렬 계산
    cov = return_data.cov(min_periods=len(return_data))

    if cov.isnull().values.any() or cov.empty:
        return None

    # 평균-분산 최적화
    ef = EfficientFrontier(
        expected_returns=expected_return,
        cov_matrix=cov,
        solver='OSQP'
    )
    ef.max_quadratic_utility(risk_aversion=risk_aversion)
    # 0에 가까운 편입비중 처리
    weights = dict(ef.clean_weights(rounding=None))
    return weights
```
-> 먼저 calculate_return 함수로 주가 데이터를 받아서 수익률 계산한 후 반환
-> 이어서 포트폴리오의 자산 편입 비중을 계산하는 get_mean_variance_weights 함수를 통해 수익률 데이터와 위험 회피 계수를 입력 파라미터로 받아 투자 포트폴리오의 자산 편입 비중을 반환


## 거래 흐름 모델링
시뮬레이션을 할 때는 현실에 가깝게 금융 환경을 모델링하고 거래 과정을 재현해 보다 정확하게 투자 전략을 평가하는 것이 중요하다. 즉 실제 거래가 발생했을 때의 상황을 재현할 수 있어야 하며 그에 따른 자산 보유 현황을 정확히 추적하는 과정이 필요하다. 이에따라 오픈 소스 시뮬레이션 패키지인 지플라인(Zipline)의 모델을 참조


<img width="415" alt="스크린샷 2024-10-09 오후 3 55 32" src="https://github.com/user-attachments/assets/e09892b8-9bb9-418a-9348-65d18116d51f">

이에 따라 각 상황에 맞는 클래스를 활용해서 주문, 거래를 시뮬레이션 함

## 시뮬레이션 결과 전처리 및 평가
계좌에는 시뮬레이션 과정의 모든 히스토리가 저장돼 있음. 시뮬레이션 결과를 분석하기 전에 전처리

<img width="201" alt="스크린샷 2024-10-09 오후 3 59 20" src="https://github.com/user-attachments/assets/a643700e-3217-4576-bfa6-ebcc62381c7a">
<br>
<img width="385" alt="스크린샷 2024-10-09 오후 4 02 59" src="https://github.com/user-attachments/assets/fdeba680-84f6-4a2b-bcc1-3260daca9928">

 평가는 해당 지표들로 성능을 확인할 수 있다


# 멀티 팩터 전략
팩터 투자는 적절한 시기와 선택한 전략이 **맞으면** 매력적일수 있다. 그러나 시장 상황을 보고 맞는 전략을 고르기란 쉽지 않다
* 주식 시장이 불황일때는 하방 지지선이 있거나 낙폭이 적은 팩터 전략이 좋을 것
* 주식 시장이 호황일 경우 공격적 성향을 보일 수 있는 전략을 선택할 수 있다
* -> 그러나 전문가도 시장을 보는 시각이 제각각인데 전문 경제 지식 없이 현재 시장의 상황을 잘 정의할 수 있는가
-> 이번 단원에서는 생각을 뒤집어서 전략 별 수익률을 바탕으로 현재 시장을 정의. 여러 전략의 여러 상황이 특정 시장 상황에 대응된다는 더 유연한 가설을 바탕으로 시장 상황 분류를 진행

## 전략별 일별 수익
* 주식 시장이 좋을 때는 모멘텀, 내실 있는 기업만 살아남을 수 있는 시기에는 가치주, 찬 바람 불때는 배당주, >> 가치주가 잘 나올 때를 기업의 버블이 꺼지는 시기, 모멘텀 전략의 성과가 좋을 때가 주식 시장의 호황기, 배당주가 잘 나올 때는 투자자들이 하방 지지선이 필요하다고 느낀다는 식으로 역해석
* 팩터의 수익률을 알기 위해서는 우선 개별 팩터의 수익률 움직임을 분석해야한다. 각 팩터의 일별 수익 변화율을 살펴보기

1. 빈도 속성을 유지하면서 데이터 자르기
전략을 실행하는 코드가 월별 및 일별 데이터를 같이 쓰기 위해서는 월별 데이터의 날짜를 조정해줘야 한다. 월별 데이터로 수집할 시 데이터 추출 과정에서 일자가 정확하지 않을 수 있기 때문이다
<br>
2. 데이터 날짜 교정
데이터를 월별로 가져올 시 데이터의 날짜는 매월 말일로 설정된다. 정확한 계산을 위해서는 월별 말일이 아닌 해당 월의 마지막 거래일이 필요하다.

3. 전략별 일별 수익 csv 만들기
이를 통해 모든 전략에 대해 일별 시뮬레이션 구동 가능 > 모든 전략을 동일한 주기로 실행해 수익률을 비교

## 경기 국면과 군집
우선 팩터의 일별 수익률을 구했다. 이제 시장 상황을 나타내는 경기 국면을 구해보자
<img width="365" alt="스크린샷 2024-10-09 오후 4 39 17" src="https://github.com/user-attachments/assets/1b9f9101-abcd-4341-9af5-9c30e775fa38">
* 호황기는 경제 활동이 활발해 지면서 경기 수준이 가속화돼 고점이 이르는 구간, 고성장과 고물가가 같이 나타나며 경기 확장 기조로 인해 모멘텀 팩터가 강세를 띄는 것으로 알려져있다
* 후퇴기에는 경기 하락 초기의 구간으로, 물가는 여전히 상승하고 경제도 전반적으로 상향하므로 해당 구간은 상대적으로 짧다
* 침체기는 경기가 하락하며 물가도 하락하는 구간이다, 투자와 생산이 극도로 줄어들고 대량 실업이 나타나며 금리도 낮아진다. 침체 구간에서 상대적으로 안정 기업의 부각 현상이 나타나면서 퀄리티 팩터가 활약한다고 알려져 있다
* 회복기는 침체기에서 서서히 벗어나는 단계로, 기업의 재고가 감소하고 투자와 생산이 늘어남에 따라 경기는 상승하고 물가는 안정되며 주가와 금리는 오르게 된다
* 이러한 경기 국면에 맞는 팩터가 있지 않을까? 경기 국면에는 4종류가 있다는 사실을 바탕으로 팩터의 수익률 또한 4개의 부류로 나누는 시도를 할 수 있다. 이러한 분류 방법 중 하나인 K-means clustering을 사용



<img width="375" alt="스크린샷 2024-10-09 오후 4 42 49" src="https://github.com/user-attachments/assets/6ede6cb0-513c-41b6-9051-5203393414dd">

* 또한 군집 개수에 따른 관성을 측정하여 군집 내 데이터와 해당 군집의 중심전 간의 거리의 제곱합을 나타내는 지표로 군집화의 품질을 측정해야 한다
  * 높은 관성은 데이터가 군집의 중심점에서 멀리 떨어져 있음을 의미하므로 군직화를 최적화하려면 관성을 최소화하는 방향으로 군집의 개수를 조정해야한다

<img width="326" alt="스크린샷 2024-10-09 오후 4 44 22" src="https://github.com/user-attachments/assets/7b5ac976-ecc3-4068-a159-4766dbce59ad">

-> 3개로 선정

<img width="313" alt="스크린샷 2024-10-09 오후 4 44 55" src="https://github.com/user-attachments/assets/ce49bf62-f5a2-4bf1-bac4-30b087023275">

-> 각 경기 국면마다 어떤 팩터가 얼마나 활약했는지 확인 가능. 경기 국면별로 각 팩터의 성능을 알 수 있으면 어떤 경기 상황에서 어떤 팩터에 가중치를 얼마나 줘야 최적의 투자를 할 수 있을지 기획 가능


## 국면 예측
* 경기 국면을 군집으로 구분했다면 이제 시장 국면 예측을 해보자
* 시장을 둘러싼 여러 거시 경기 변수가 팩터의 효율과 연관돼 있고 경기 상황을 결정짓는다고 볼 수 있다
  * 금리가 오르면서 장단기 금리차가 상승하면 경기가 좋아질 전망으로 가치주에 주목할 수 있다
  * 해외 주식 시장의 지수가 오르면 상대적으로 국내 주식에 대한 관심이 떨어져서 국내 시장의 약세를 예측할 수 있다
* 하지만 모든 거시 경기 요소를 경기 국면과 연결 짓기는 전문가가 아닌 이상 어려운 일이다
<img width="386" alt="스크린샷 2024-10-09 오후 4 52 28" src="https://github.com/user-attachments/assets/1c7e8fa9-7233-4586-b3d7-58f308c80c4f">

```python
fromdate = '2012-11-01'
todate = '2021-12-30'
macro_name = [
    # 주요 지수
    'KS200',  # 코스피 200
    'US500',  # S&P 500 지수
    'SSEC',  # 상해 종합
    'VIX',  # 공포지수

    # 상품 선물
    'CL',  # WTI유 선물 Crude Oil (NYMEX)
    'GC',  # 금 선물 (COMEX)
    'HG=F',  # 구리 선물 (COMEX)

    # 환율
    'KRW/USD',  # 달러 원화
    'KRW/CNY',  # 달러 위엔화

    # 채권
    'US5YT',  # 5년 만기 미국국채 수익률
    'US30YT',  # 30년 만기 미국국채 수익률
    'FRED:T10Y3M',  # 미국 장단기금리차(10Y-3M) : 연준에서 중시하는 10년-3개월 금리차

    # 경기 지표(미국)
    'FRED:M1SL',  # M1 통화량
    'FRED:M2',  # M2 통화량
    'FRED:HSN1F',  # HSN1F 주택판매지수
    'FRED:T5YIFR',  # 5년 기대인플레이션
    'FRED:UNRATE',  # 미국 실업률

    # 경기 지표(한국)
    'FRED:MANMM101KRM189S',  # 대한민국 M1 통화량
    'FRED:MYAGM2KRM189S',  # 대한민국 M2 통화량
    'FRED:KORCPIALLMINMEI',  # 한국 소비자물가지수: 모든 항목
    'FRED:KORLOLITONOSTSAM',  # OECD 선행지수: 대한민국용 정규화된 선행지수
    'FRED:XTEXVA01KRM664S',  # 대한민국 수출: 상품 가치
    'FRED:XTIMVA01KRM667S',  # 대한민국 수입: 상품 가치
]

def macro_data_loader(fromdate: str, todate: str,
                      data_list: list) -> pd.DataFrame:
    df = pd.DataFrame({'DATE': pd.date_range(start=fromdate, end=todate)})
    for data_name in data_list:
        # 데이터 로드하기
        df_sub = fdr.DataReader(data_name, fromdate, todate)
        # OHLCV 데이터면 Close만 사용
        if 'Close' in df_sub.columns:
            df_sub = df_sub[['Close']]
            df_sub.rename(columns={'Close': data_name}, inplace=True)
        df = df.merge(df_sub, how='left', left_on='DATE', right_index=True)

    return df.rename(columns={"DATE": "date"})
```
<img width="403" alt="스크린샷 2024-10-09 오후 5 06 04" src="https://github.com/user-attachments/assets/a92fd47c-766f-4e94-9429-9f45e9f4a8bc">
-> 이후 모델링을 거치고


<img width="419" alt="스크린샷 2024-10-09 오후 5 06 10" src="https://github.com/user-attachments/assets/df79286a-0bc2-4968-8de6-202decddacdc">
-> 실제 군집과 분류가 어떻게 됐는지 평가하고



<img width="389" alt="스크린샷 2024-10-09 오후 5 05 57" src="https://github.com/user-attachments/assets/8545d31f-60e5-409e-a3f8-872dfddee59b">
-> 이를 기반으로 전략별 편입 비중을 전략별 가중치와 곱해서 최종 멀티 팩터 포트폴리오를 구한다


<img width="409" alt="스크린샷 2024-10-09 오후 5 07 52" src="https://github.com/user-attachments/assets/b8686fd1-be30-4566-9f75-cc6b4060b27f">
<br>
<img width="385" alt="스크린샷 2024-10-09 오후 5 07 49" src="https://github.com/user-attachments/assets/45dbe6af-b9fc-4c59-8bdf-c216bfafc907">

* 결과는 이러하다
  * 연간 수익률에서 멀티 팩터 전략은 소형주의 뒤를 이어 연 약 21%의 수익률을 기록했다
  * 샤프비율과 소티노 비율 또한 소형주 전략의 뒤를 이어 좋은 성능을 보인다
  * 다만 최대 손실 낙폭에서는 다른 전략에 비해 좋은 지표를 나타내지는 못한다
  * 분산을 통해 폭락장을 이겨냈어야할 멀티 팩터 전략이 분산에 실패한 모습을 보이는 이유로 실제로 줘야할 가중치와는 달리 예측에서 로우볼 전략과 개인 수급 주체 전략에 많은 가중치를 줬기 때문으로 추측된다
  * 또한 최소 가중치라는 인위적 조건이 위험 회피에 약영향을 줬을 수도 있다
  * 멀티 팩터 전략의 성능 향상을 위해서는 전략 가중치를 더 효과적이라고 판된되는 전략에 많이 주거나 더 정확한 예측을 해 효율적이고 예방적인 분산을 가능하게 할 수도 있다
  * 특히 구성하는 팩터의 영향을 많이 받는 멀티 팩터 전략의 특성상 더욱 좋은 팩터를 많이 개발해 멀티 팩터 전략의 구성 요소에 포함시키고 저조한 성능을 보이는 팩터 전략을 제외한다면 멀티 팩터 전략은 수익률 뿐만 아니라 최대 손실 낙폭 성능 또한 향상시킬 수 있을 것이다

















   


















